{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import gc\n",
    "from dython.nominal import associations\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c6e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "def extract_horsepower(engine):\n",
    "    ''' Extracts horsepower from engine string'''\n",
    "    try:\n",
    "        return float(engine.split('HP')[0])\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def extract_engine_size(engine):\n",
    "    ''' Extracts engine size from engine string'''\n",
    "    try:\n",
    "        return float(engine.split(' ')[1].replace('L', ''))\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "        \n",
    "def feature_engineering(df_engine):\n",
    "    \n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    df_engine['age'] = current_year - df_engine['model_year']\n",
    "    df_engine['milage_per_year'] = df_engine['milage']/df_engine['age']\n",
    "\n",
    "    df_engine['horsepower'] = df_engine['engine'].apply(extract_horsepower)\n",
    "    df_engine['engine_size'] = df_engine['engine'].apply(extract_engine_size)\n",
    "    df_engine['power_to_weight_ratio'] = df_engine['horsepower']/df_engine['engine_size']\n",
    "\n",
    "    luxury_brands =  ['Mercedes-Benz', 'BMW', 'Audi', 'Porsche', 'Land', \n",
    "                    'Lexus', 'Jaguar', 'Bentley', 'Maserati', 'Lamborghini', \n",
    "                    'Rolls-Royce', 'Ferrari', 'McLaren', 'Aston', 'Maybach']\n",
    "    #df_clean['Is_Luxury_Brand'] = df_clean['brand'].apply(lambda x: 1 if x in luxury_brands else 0)\n",
    "\n",
    "    #df_clean['Accident_Impact'] = df_clean.apply(lambda x: 1 if x['accident'] == 1 and x['clean_title'] == 0 else 0, axis=1)\n",
    "    \n",
    "    return df_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd17b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrar outliers en price\n",
    "\n",
    "def filtrar_outliers_price(df, col='price', factor=1.5):\n",
    "    ''' \n",
    "    Filtra outliers en una columna numérica utilizando el método del rango intercuartílico (IQR);\n",
    "    retorna - DataFrame sin outliers\n",
    "    '''\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inf = Q1 - factor * IQR\n",
    "    limite_sup = Q3 + factor * IQR\n",
    "    df_filtrado = df[(df[col] >= limite_inf) & (df[col] <= limite_sup)].reset_index(drop=True)\n",
    "    print(f\"Filtrado: {len(df) - len(df_filtrado)} filas eliminadas ({100*(1 - len(df_filtrado)/len(df)):.2f}%)\")\n",
    "    return df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(X_train, y_train, X_test, y_test, categorical_cols):\n",
    "    ''' entrena un modelo CatBoostRegressor y retorna el modelo entrenado'''\n",
    "    \n",
    "    catboost_model = CatBoostRegressor(\n",
    "        iterations=1500,\n",
    "        learning_rate=0.07,\n",
    "        depth=4,\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    catboost_model.fit(\n",
    "        X_train, y_train,\n",
    "        cat_features=categorical_cols,\n",
    "        eval_set=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    return catboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    ''' evalua el modelo entrenado y retorna las metricas RMSE y R2 para train y test'''\n",
    "    \n",
    "    # predicciones\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # metricas\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    \n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    overfitting_pct = (rmse_test - rmse_train) / rmse_train * 100\n",
    "\n",
    "    print(f\"RMSE Train: {rmse_train:.2f} | R2 Train: {r2_train:.2f}\")\n",
    "    print(f\"RMSE Test : {rmse_test:.2f} | R2 Test : {r2_test:.2f}\")\n",
    "    print(f\"Overfitting relativo: {overfitting_pct:.2f}%\")\n",
    "\n",
    "    # medir outfitting\n",
    "    #rmse_train = catboost_model.get_best_score()['learn']['RMSE']\n",
    "    #rmse_test = catboost_model.get_best_score()['validation']['RMSE']\n",
    "\n",
    "    overfitting_pct = (rmse_test - rmse_train) / rmse_train * 100\n",
    "    print(f\"Overfitting relativo: {overfitting_pct:.2f}%\")\n",
    "    \n",
    "    return rmse_train, r2_train, rmse_test, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93420ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reentrenar el modelo \n",
    "def retrain_full_model(X, y, categorical_cols, save_path = '../models/catboost_final_model.cbm'):\n",
    "    \n",
    "    ''' reentrena el modelo con todo el dataset (train + test) y retorna/guarda el modelo final'''\n",
    "    \n",
    "    final_model = CatBoostRegressor(\n",
    "        iterations=1500,\n",
    "        learning_rate=0.07,\n",
    "        depth=4,\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "    )\n",
    "    final_model.fit(X, y, cat_features=categorical_cols)\n",
    "    final_model.save_model(save_path)\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cf8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(train_df):\n",
    "    ''' Prepara el dataset para el entrenamiento del modelo CatBoost; retorna - X, y, categorical_cols'''\n",
    "    # Apply feature engineering in the training set\n",
    "    feature_engineering(train_df)\n",
    "    train_df = train_df.dropna().reset_index(drop=True)\n",
    "    train_df = train_df.drop(['model_year','engine', 'clean_title'],axis=1)\n",
    "    train_df.drop('id',inplace=True,axis=1) # remove 'id' column from both training\n",
    "\n",
    "    # filtrar outliers en price\n",
    "    train_df = filtrar_outliers_price(train_df)\n",
    "    # Crear columna 'coches_ultralujo'\n",
    "    train_df['coches_ultralujo'] = np.where(train_df['price'] > 150000, 'ultralujo', 'normal')\n",
    "\n",
    "    # separar features y target\n",
    "    X = train_df.drop('price', axis=1)\n",
    "    y = train_df['price']\n",
    "\n",
    "    # identificar columnas categoricas\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    return X, y, categorical_cols\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daeba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINCIPAL\n",
    "\n",
    "# cargar datos\n",
    "train_df = pd.read_csv('../datasets/train.csv')\n",
    "\n",
    "# preparar datos\n",
    "X, y, categorical_cols = pretrain(train_df)\n",
    "\n",
    "# dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42)\n",
    "\n",
    "# entrenar modelo\n",
    "catboost_model = train_catboost(X_train, y_train, X_test, y_test, categorical_cols)\n",
    "\n",
    "# evaluar modelo\n",
    "evaluate_model(catboost_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# reentrenar el modelo con todo el dataset y guardar el modelo final\n",
    "final_model = retrain_full_model(X, y, categorical_cols, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ddc3bd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
