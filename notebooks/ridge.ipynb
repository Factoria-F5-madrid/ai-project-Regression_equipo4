{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060887a1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-19T10:16:57.267099Z",
     "iopub.status.busy": "2025-09-19T10:16:57.266751Z",
     "iopub.status.idle": "2025-09-19T10:16:59.458045Z",
     "shell.execute_reply": "2025-09-19T10:16:59.456692Z"
    },
    "papermill": {
     "duration": 2.196604,
     "end_time": "2025-09-19T10:16:59.459949",
     "exception": false,
     "start_time": "2025-09-19T10:16:57.263345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13545db1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T10:16:59.465742Z",
     "iopub.status.busy": "2025-09-19T10:16:59.465230Z",
     "iopub.status.idle": "2025-09-19T10:17:00.386423Z",
     "shell.execute_reply": "2025-09-19T10:17:00.385046Z"
    },
    "papermill": {
     "duration": 0.925914,
     "end_time": "2025-09-19T10:17:00.388128",
     "exception": false,
     "start_time": "2025-09-19T10:16:59.462214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../datasets/train.csv')\n",
    "'''Removing the 'id' column is a common preprocessing step in machine learning workflows.\n",
    "id's do not carry predictive information and could interfere with model training if left in the dataset.\n",
    " By dropping this column from both training and test sets, you ensure that only relevant features are used for modeling'''\n",
    "train_df.drop('id',inplace=True,axis=1)\n",
    "print('Columns:', list(train_df.columns))\n",
    "print('Info:')\n",
    "train_df.info()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pseudonull values and uniqueness faults\n",
    "print(\"\\nUnique values in each column (nan is not a value):\")\n",
    "for col in train_df.columns:\n",
    "    print(f\"{col}: {train_df[col].nunique()} unique values\")\n",
    "    if col != \"id\":\n",
    "        try:\n",
    "            unique_vals = train_df[col].unique()\n",
    "            # Convert to string to handle mixed types, then sort\n",
    "            unique_vals_str = [str(val) for val in unique_vals]\n",
    "            print(f\"  Values: {sorted(unique_vals_str)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Values: {list(train_df[col].unique())}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee5a45",
   "metadata": {},
   "source": [
    "\"brand\" column has no pseudonull values and unique values are OK\n",
    "\"model\" column has no pseudonull values and unique values are OK\n",
    "\"model_year\" column has no pseudonull values and unique values are OK\n",
    "\"mileage\" column has no pseudonull values and unique values are OK\n",
    "\"fuel_type\" column has pseudonull values \"-\"\n",
    "\"engine\" column has pseudonull values \"-\"\n",
    "\"transmission\" column has pseudonull values \"-\"\n",
    "\"ext_col\" column has pseudonull values \"-\"\n",
    "\"int_col\" column has pseudonull values \"-\"\n",
    "\"accident\" column has no pseudonull values and unique values are OK\n",
    "\"clean_title\" column has no pseudonull values and unique values are OK\n",
    "\"price\" column has no pseudonull values and unique values are OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"-\" values by nan\n",
    "df_clean = train_df.copy()\n",
    "missing_values = ['-', '—', '–', '−']\n",
    "df_clean = df_clean.replace(missing_values, np.nan)\n",
    "print('Info after replacing \"-\" by nan:')\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda75ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_clean, figsize=(12, 8))\n",
    "plt.title('Missing Values distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicate rows\n",
    "duplicates = df_clean[df_clean.duplicated(keep=False)]#df_clean.duplicated(keep=False) returns a boolean Series indicating if a row is duplicated in the  DataFrame\n",
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c260c",
   "metadata": {},
   "source": [
    "There are no duplicate rows in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def feature_engineering(df_clean):\n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    df_clean['age'] = current_year - df_clean['model_year']\n",
    "    df_clean['milage_per_year'] = df_clean['milage']/df_clean['age']\n",
    "\n",
    "    def extract_horsepower(engine):\n",
    "        try:\n",
    "            return float(engine.split('HP')[0])\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def extract_engine_size(engine):\n",
    "        try:\n",
    "            return float(engine.split(' ')[1].replace('L', ''))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df_clean['horsepower'] = df_clean['engine'].apply(extract_horsepower)# when splitting fails nan values are assigned\n",
    "    df_clean['engine_size'] = df_clean['engine'].apply(extract_engine_size)\n",
    "    df_clean['power_to_weight_ratio'] = df_clean['horsepower']/df_clean['engine_size']\n",
    "\n",
    "    luxury_brands =  ['Mercedes-Benz', 'BMW', 'Audi', 'Porsche', 'Land', \n",
    "                    'Lexus', 'Jaguar', 'Bentley', 'Maserati', 'Lamborghini', \n",
    "                    'Rolls-Royce', 'Ferrari', 'McLaren', 'Aston', 'Maybach']\n",
    "    df_clean['Is_Luxury_Brand'] = df_clean['brand'].apply(lambda x: 1 if x in luxury_brands else 0)\n",
    "\n",
    "    df_clean['Accident_Impact'] = df_clean.apply(lambda x: 1 if x['accident'] == 1 and x['clean_title'] == 0 else 0, axis=1)\n",
    "    # Nan values are generated throug feature enginereeing. Drop rows with any NaN values after feature extraction\n",
    "    df_clean = df_clean.dropna()\n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2686c1c",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "Now that we have cleaned our dataset, let´s get its metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eada93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIVARIATE VISUALIZATIONS\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"UNIVARIATE ANALYSIS - VISUALIZATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (15, 30)  # taller for 12 plots\n",
    "\n",
    "# 1. NUMERIC VARIABLES PLOTS\n",
    "numeric_columns = df_clean.select_dtypes(include=['number']).columns\n",
    "n_cols = 3\n",
    "n_rows = 6\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 30))\n",
    "fig.suptitle('Univariate Analysis - Numeric Variables', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, col in enumerate(numeric_columns):\n",
    "    row = idx // n_cols\n",
    "    col_idx = idx % n_cols\n",
    "    # Histogram in the upper half of each cell\n",
    "    if col == 'Accident_Impact':\n",
    "        axes[row, col_idx].hist(df_clean[col].dropna(), bins=[-0.5,0.5,1.5], alpha=0.7, color='skyblue', edgecolor='black', rwidth=0.8)\n",
    "        axes[row, col_idx].set_xlim(-0.1, 1.1)\n",
    "        axes[row, col_idx].set_xticks([0, 1])\n",
    "    else:\n",
    "        axes[row, col_idx].hist(df_clean[col].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[row, col_idx].set_title(f'{col} - Distribution', fontweight='bold')\n",
    "    axes[row, col_idx].set_xlabel(col)\n",
    "    axes[row, col_idx].set_ylabel('Frequency')\n",
    "    axes[row, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide any unused subplots (remove empty histograms)\n",
    "for idx in range(len(numeric_columns), n_rows * n_cols):\n",
    "    row = idx // n_cols\n",
    "    col_idx = idx % n_cols\n",
    "    fig.delaxes(axes[row, col_idx])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.5, 1, 0.97])\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for numeric columns\n",
    "fig2, axes2 = plt.subplots(n_rows, n_cols, figsize=(18, 30))\n",
    "fig2.suptitle('Univariate Analysis - Numeric Variables (Boxplots)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, col in enumerate(numeric_columns):\n",
    "    row = idx // n_cols\n",
    "    col_idx = idx % n_cols\n",
    "    axes2[row, col_idx].boxplot(df_clean[col].dropna(), patch_artist=True, boxprops=dict(facecolor='lightgreen', alpha=0.7))\n",
    "    axes2[row, col_idx].set_title(f'{col} - Box Plot', fontweight='bold')\n",
    "    axes2[row, col_idx].set_ylabel(col)\n",
    "    axes2[row, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide any unused subplots in boxplots\n",
    "for idx in range(len(numeric_columns), n_rows * n_cols):\n",
    "    row = idx // n_cols\n",
    "    col_idx = idx % n_cols\n",
    "    fig2.delaxes(axes2[row, col_idx])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd4a86",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc1f6f9",
   "metadata": {},
   "source": [
    "## Ridge model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge model training with RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "X = df_clean.drop(columns=['price'])\n",
    "y = df_clean['price']\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "num_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ('num', RobustScaler(), num_cols)\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('reg', Ridge(alpha=1.0, random_state=1, max_iter=1000))\n",
    "])\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "val_predictions = model.predict(val_X)\n",
    "train_predictions = model.predict(train_X)\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def make_html_table(df, title):\n",
    "    html = f'<b>{title}</b><br><table><tr>'\n",
    "    for col in df.columns:\n",
    "        html += f'<th>{col}</th>'\n",
    "    html += '</tr>'\n",
    "    for _, row in df.iterrows():\n",
    "        html += '<tr>' + ''.join(f'<td>{v}</td>' for v in row) + '</tr>'\n",
    "    html += '</table>'\n",
    "    return html\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'Validation Prediction': val_predictions[:5],\n",
    "    'Validation Actual': list(val_y[:5])\n",
    "})\n",
    "train_df = pd.DataFrame({\n",
    "    'Train Prediction': train_predictions[:5],\n",
    "    'Train Actual': list(train_y[:5])\n",
    "})\n",
    "\n",
    "output = []\n",
    "output.append(\"<br>\" + \"=\"*60)\n",
    "output.append(\"RIDGE REGRESSOR RESULTS\")\n",
    "output.append(\"=\"*60)\n",
    "output.append(make_html_table(val_df, \"Validation Set (Top 5)\"))\n",
    "output.append(make_html_table(train_df, \"Training Set (Top 5)\"))\n",
    "output.append(\"-\"*60)\n",
    "val_mae = mean_absolute_error(val_y, val_predictions)\n",
    "train_mae = mean_absolute_error(train_y, train_predictions)\n",
    "val_r2 = r2_score(val_y, val_predictions)\n",
    "train_r2 = r2_score(train_y, train_predictions)\n",
    "output.append(f\"Validation MAE: {val_mae:.2f}\")\n",
    "output.append(\"<br>\")\n",
    "output.append(f\"Training MAE: {train_mae:.2f}\")\n",
    "output.append(\"<br>\")\n",
    "output.append(f\"Validation R2: {val_r2:.3f}\")\n",
    "output.append(\"<br>\")\n",
    "output.append(f\"Training R2: {train_r2:.3f}\")\n",
    "display(Markdown('  \\n'.join(output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c8ad6a",
   "metadata": {},
   "source": [
    "## Train model with whole dataset and create csv file with predictions to feed it into the frontend"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9057646,
     "sourceId": 76728,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.775794,
   "end_time": "2025-09-19T10:17:01.011402",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-19T10:16:51.235608",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
